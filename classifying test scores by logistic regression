import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
plt.style.use("ggplot")
%matplotlib inline
from pylab import rcParams
rcParams['figure.figsize'] = 12, 8
data = pd.read_csv(("DMV_Written_Tests.csv"))
data.head()
scores = data[['DMV_Test_1','DMV_Test_2']].values
results = data ['Results'].values
passed = (results == 1).reshape(100,1)
failed = (results == 0).reshape(100,1)
plt.scatter(scores[passed[:,0],0],scores[passed[:,0],1],marker = "^",color = "green",s = 100)
plt.scatter(scores[failed[:,0],0],scores[failed[:,0],1],marker = "*",color = "red",s = 100)
def logistic_function(x):
    return 1/(1+np.exp(-x))
def compute_cost(theta,x,y):
    m = len(y)
    y_pred = logistic_function(np.dot(x,theta))
    error = (y*np.log(y_pred)) + (1-y)*np.log(1-y_pred)
    cost = -1/m * sum(error)
    gradient = 1/m * np.dot(x.transpose(),(y_pred-y))
    return cost[0],gradient
mean_scores = np.mean(scores,axis=0)
std_scores = np.std(scores,axis = 0)
scores = (scores-mean_scores)/std_scores
rows = scores.shape[0]
cols = scores.shape[1]
x = np.append(np.ones((rows,1)),scores,axis = 1)
y = results.reshape(rows,1)
theta_init = np.zeros((cols+1,1))
cost,gradient = compute_cost(theta_init,x,y)
print(cost,gradient)
def gradient_descent(x,y,theta,alpha,iterations):
    costs = []
    for i in range(iterations):
        cost,gradient = compute_cost(theta,x,y)
        theta = theta - (alpha*gradient)
        costs.append(cost)
    return theta,costs
theta,costs = gradient_descent(x,y,theta_init,1,200)
print(theta,costs[-1])
plt.plot(costs)
plt.xlabel("itr")
plt.ylabel("J(/Theta)")
plt.scatter(x[passed[:,0],1],x[passed[:,0],2],marker = "^",color = "green",s = 100)
plt.scatter(scores[failed[:,0],0],scores[failed[:,0],1],marker = "*",color = "red",s = 100)
x_b = np.array([np.min(x[:,1]),np.max(x[:,1])])
y_b = -(theta[0]+theta[1]*x_b)/theta[2]
plt.plot(x_b,y_b,color = "blue")
def predict(theta,x):
    results = logistic_function(x.dot(theta))
    return results>0.6
p = predict(theta,x)
d = sum(p==y)[0]
d

